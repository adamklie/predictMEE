{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Train-a-bi-LSTM-to-predict-short-entities\" data-toc-modified-id=\"Train-a-bi-LSTM-to-predict-short-entities-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Train a bi-LSTM to predict short entities<br></a></span><ul class=\"toc-item\"><li><span><a href=\"#Set-up\" data-toc-modified-id=\"Set-up-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Set up</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-necessry-packages\" data-toc-modified-id=\"Import-necessry-packages-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Import necessry packages</a></span></li><li><span><a href=\"#Helper-functions\" data-toc-modified-id=\"Helper-functions-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Helper functions</a></span></li><li><span><a href=\"#Load-in-data\" data-toc-modified-id=\"Load-in-data-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Load in data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Read-in-the-BioSample-annotations-and-build-dataframe\" data-toc-modified-id=\"Read-in-the-BioSample-annotations-and-build-dataframe-1.1.3.1\"><span class=\"toc-item-num\">1.1.3.1&nbsp;&nbsp;</span>Read in the BioSample annotations and build dataframe</a></span></li><li><span><a href=\"#Read-in-metadata-on-BioSample-entries-that-will-allow-us-to-cap-on-study\" data-toc-modified-id=\"Read-in-metadata-on-BioSample-entries-that-will-allow-us-to-cap-on-study-1.1.3.2\"><span class=\"toc-item-num\">1.1.3.2&nbsp;&nbsp;</span>Read in metadata on BioSample entries that will allow us to cap on study</a></span></li><li><span><a href=\"#Read-in-embeddings\" data-toc-modified-id=\"Read-in-embeddings-1.1.3.3\"><span class=\"toc-item-num\">1.1.3.3&nbsp;&nbsp;</span>Read in embeddings</a></span></li><li><span><a href=\"#Import-merging-of-entities-from-file\" data-toc-modified-id=\"Import-merging-of-entities-from-file-1.1.3.4\"><span class=\"toc-item-num\">1.1.3.4&nbsp;&nbsp;</span>Import merging of entities from file</a></span></li></ul></li></ul></li><li><span><a href=\"#Data-processing\" data-toc-modified-id=\"Data-processing-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Data processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Filter-training-set\" data-toc-modified-id=\"Filter-training-set-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Filter training set</a></span><ul class=\"toc-item\"><li><span><a href=\"#Filter-out-non-valid-attributes\" data-toc-modified-id=\"Filter-out-non-valid-attributes-1.2.1.1\"><span class=\"toc-item-num\">1.2.1.1&nbsp;&nbsp;</span>Filter out non-valid attributes</a></span></li><li><span><a href=\"#Cap-at-100-samples-per-study-to-avoid-study-bias\" data-toc-modified-id=\"Cap-at-100-samples-per-study-to-avoid-study-bias-1.2.1.2\"><span class=\"toc-item-num\">1.2.1.2&nbsp;&nbsp;</span>Cap at 100 samples per study to avoid study bias</a></span></li><li><span><a href=\"#Filter-out-unwanted-training-examples-and-replace-all-white-space-with-'-'\" data-toc-modified-id=\"Filter-out-unwanted-training-examples-and-replace-all-white-space-with-'-'-1.2.1.3\"><span class=\"toc-item-num\">1.2.1.3&nbsp;&nbsp;</span>Filter out unwanted training examples and replace all white space with ' '</a></span></li><li><span><a href=\"#Take-only-values-between-length-2-and-7\" data-toc-modified-id=\"Take-only-values-between-length-2-and-7-1.2.1.4\"><span class=\"toc-item-num\">1.2.1.4&nbsp;&nbsp;</span>Take only values between length 2 and 7</a></span></li><li><span><a href=\"#Filter-out-test-set-examples\" data-toc-modified-id=\"Filter-out-test-set-examples-1.2.1.5\"><span class=\"toc-item-num\">1.2.1.5&nbsp;&nbsp;</span>Filter out test set examples</a></span></li><li><span><a href=\"#Replace-whitespace-with-'-'\" data-toc-modified-id=\"Replace-whitespace-with-'-'-1.2.1.6\"><span class=\"toc-item-num\">1.2.1.6&nbsp;&nbsp;</span>Replace whitespace with ' '</a></span></li><li><span><a href=\"#Final-dataset\" data-toc-modified-id=\"Final-dataset-1.2.1.7\"><span class=\"toc-item-num\">1.2.1.7&nbsp;&nbsp;</span>Final dataset</a></span></li></ul></li><li><span><a href=\"#Train/val-split\" data-toc-modified-id=\"Train/val-split-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Train/val split</a></span><ul class=\"toc-item\"><li><span><a href=\"#Start-by-pulling-out-only-samples-that-are-in-our-dataset-from-technical-metadata,-that-has-studies-in-it\" data-toc-modified-id=\"Start-by-pulling-out-only-samples-that-are-in-our-dataset-from-technical-metadata,-that-has-studies-in-it-1.2.2.1\"><span class=\"toc-item-num\">1.2.2.1&nbsp;&nbsp;</span>Start by pulling out only samples that are in our dataset from technical metadata, that has studies in it</a></span></li><li><span><a href=\"#Get-unique-studies\" data-toc-modified-id=\"Get-unique-studies-1.2.2.2\"><span class=\"toc-item-num\">1.2.2.2&nbsp;&nbsp;</span>Get unique studies</a></span></li><li><span><a href=\"#Select-studies-to-use-to-train-and-validate\" data-toc-modified-id=\"Select-studies-to-use-to-train-and-validate-1.2.2.3\"><span class=\"toc-item-num\">1.2.2.3&nbsp;&nbsp;</span>Select studies to use to train and validate</a></span></li></ul></li><li><span><a href=\"#Generate-training-and-val-dataframes\" data-toc-modified-id=\"Generate-training-and-val-dataframes-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Generate training and val dataframes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-set\" data-toc-modified-id=\"Training-set-1.2.3.1\"><span class=\"toc-item-num\">1.2.3.1&nbsp;&nbsp;</span>Training set</a></span></li><li><span><a href=\"#Validation-set\" data-toc-modified-id=\"Validation-set-1.2.3.2\"><span class=\"toc-item-num\">1.2.3.2&nbsp;&nbsp;</span>Validation set</a></span></li></ul></li><li><span><a href=\"#Supp.-Figure-2A-Class-balance\" data-toc-modified-id=\"Supp.-Figure-2A-Class-balance-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span><font color=\"red\">Supp. Figure 2A</font> Class balance</a></span></li></ul></li><li><span><a href=\"#Train-the-model\" data-toc-modified-id=\"Train-the-model-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Train the model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-set-up\" data-toc-modified-id=\"Model-set-up-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Model set-up</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train a bi-LSTM to predict short entities<br>\n",
    "Adam Klie<br>\n",
    "11/17/2019<br>\n",
    "Script to train a model based on merged entities passed in and training set decided on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Import necessry packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true,
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential, model_from_json, load_model\n",
    "from keras.layers import LSTM, Dense, Embedding, Bidirectional\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from sklearn import preprocessing, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Function to build LSTM model.\n",
    "# embeddings: an mxn matrix of word embeddings with m words and n features for each word (this case is 5443656 x 200)\n",
    "# shape: parameter split into number of hidden units, \n",
    "def compile_lstm(embeddings, shape, settings):  # function definition\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(embeddings.shape[0],\n",
    "                        embeddings.shape[1],\n",
    "                        input_length=shape['max_length'],\n",
    "                        trainable=False,\n",
    "                        weights=[embeddings],\n",
    "                        mask_zero=True))\n",
    "    \n",
    "    #the same dense layer is first applied extract the most useful info from embedding layers\n",
    "    model.add(TimeDistributed(Dense(shape['nr_hidden'], use_bias=False)))\n",
    "    model.add(Bidirectional(LSTM(shape['nr_hidden'],\n",
    "                                 recurrent_dropout=settings['dropout'],\n",
    "                                 dropout=settings['dropout'])))\n",
    "    model.add(Dense(shape['nr_class'], activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(lr=settings['lr']), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def get_features(docs, max_length):\n",
    "    docs = list(docs)\n",
    "    Xs = np.zeros((len(docs), max_length), dtype='int32')\n",
    "    for i, doc in tqdm(enumerate(docs),total=len(docs)):\n",
    "        j = 0\n",
    "        for token in doc:\n",
    "            ##rever to word vector\n",
    "            vector_id = token.vocab.vectors.find(key=token.orth)\n",
    "            if vector_id >= 0:\n",
    "                Xs[i, j] = vector_id\n",
    "            else:\n",
    "                Xs[i, j] = 0\n",
    "            j += 1\n",
    "            if j >= max_length:\n",
    "                break\n",
    "    return Xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Load in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Read in the BioSample annotations and build dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read in pandas Series from file\n",
    "SRS_dir = \"../data/allSRS_05_15_2018.pickle\"\n",
    "allSRS = pd.read_pickle(SRS_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Read in metadata on BioSample entries that will allow us to cap on study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sra_dump_pickle_dir = '../data/sra_dump.pickle'\n",
    "technical_meta_data_df = pd.read_pickle(sra_dump_pickle_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Read in embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('../data/wikipedia-pubmed-and-PMC-w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Import merging of entities from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_iter = '11_class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouping_df = pd.read_csv('../results/embedding/{model}/entity_merging.csv'.format(model = model_iter))\n",
    "#grouping_df = pd.read_csv('../../deep_clean/results/model_v1/merging/entity_merging_model_v1.csv')\n",
    "myAttribs = grouping_df.attribute.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Filter training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Filter out non-valid attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "attribute_m = allSRS.index.get_level_values(1).isin(myAttribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subset_SRS = allSRS[attribute_m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Cap at 100 samples per study to avoid study bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples left after capping: 2348023\n"
     ]
    }
   ],
   "source": [
    "max_sample_per_study_n = 100\n",
    "capped_samples = technical_meta_data_df.groupby('Study').head(n = max_sample_per_study_n)['Sample']\n",
    "print(\"Number of samples left after capping: %d\" % (len(capped_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "capped_m = subset_SRS.index.get_level_values(0).isin(capped_samples.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subset_SRS = subset_SRS[capped_m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Filter out unwanted training examples and replace all white space with ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filterTextL = ['not collected','not applicable','missing','n[/]?a','unknown', '-', '--', 'none', 'no']\n",
    "filterTextRegex = \"|\".join(map(lambda myStr:'(?:{})'.format(myStr), filterTextL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "regex_m = subset_SRS.str.contains(filterTextRegex, case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subset_SRS = subset_SRS[~regex_m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Take only values between length 2 and 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "attribute_wc = subset_SRS.str.count(' ') + 1\n",
    "wc_m = (attribute_wc >= 2) & (attribute_wc <= 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subset_SRS = subset_SRS[wc_m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Filter out test set examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('../results/validation/{model}/validation_SRSs.txt'.format(model=model_iter), 'r') as f:\n",
    "    test_srs = [line.rstrip('\\n') for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_m = ~subset_SRS.index.get_level_values(0).isin(test_srs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subset_SRS = subset_SRS[test_m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Replace whitespace with ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subset_SRS = subset_SRS.str.replace('\\s+', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subset_df = pd.DataFrame(subset_SRS).reset_index()\n",
    "subset_df.columns = ['srs', 'attribute', 'value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subset_df['original_attribute'] = subset_df['attribute']\n",
    "AttribToGroupNameS = grouping_df.groupby('attribute')['GroupName'].first()\n",
    "subset_df['attribute'] = AttribToGroupNameS[subset_df['original_attribute'].values].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srs</th>\n",
       "      <th>attribute</th>\n",
       "      <th>value</th>\n",
       "      <th>original_attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRS1024493</td>\n",
       "      <td>Species</td>\n",
       "      <td>Camellia oleifera</td>\n",
       "      <td>SCIENTIFIC_NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRS568274</td>\n",
       "      <td>Species</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>nat-host</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ERS1412828</td>\n",
       "      <td>Species</td>\n",
       "      <td>Pundamilia nyererei</td>\n",
       "      <td>SCIENTIFIC_NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRS1219231</td>\n",
       "      <td>Species</td>\n",
       "      <td>Salmonella enterica subsp. enterica</td>\n",
       "      <td>SCIENTIFIC_NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRS1219231</td>\n",
       "      <td>Species</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>host</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          srs attribute                                value  \\\n",
       "0  SRS1024493   Species                    Camellia oleifera   \n",
       "1   SRS568274   Species                         Homo sapiens   \n",
       "2  ERS1412828   Species                  Pundamilia nyererei   \n",
       "3  SRS1219231   Species  Salmonella enterica subsp. enterica   \n",
       "4  SRS1219231   Species                         Homo sapiens   \n",
       "\n",
       "  original_attribute  \n",
       "0    SCIENTIFIC_NAME  \n",
       "1           nat-host  \n",
       "2    SCIENTIFIC_NAME  \n",
       "3    SCIENTIFIC_NAME  \n",
       "4               host  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Train/val split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Start by pulling out only samples that are in our dataset from technical metadata, that has studies in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "valid_srs_m = allSRS.index.get_level_values(0).unique()\n",
    "technical_meta_data_df_sub = technical_meta_data_df[technical_meta_data_df.Sample.isin(valid_srs_m)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Get unique studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "study_s = technical_meta_data_df_sub['Study'].drop_duplicates()  # Get unique studies that can be found in allSRS\n",
    "num_studies = len(study_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Select studies to use to train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_test_ratio = 0.8\n",
    "train_n = int(num_studies * train_test_ratio)  # Number of training studies\n",
    "train_studies = study_s.sample(n = train_n, random_state = 0).values  # pick those training studies randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Label these studies with a column\n",
    "technical_meta_data_df_sub['Train'] = technical_meta_data_df_sub['Study'].isin(train_studies).values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get the ids for the training and test samples\n",
    "train_mask = technical_meta_data_df_sub['Train']\n",
    "train_samples = technical_meta_data_df_sub['Sample'][train_mask].values  # IDs for training set\n",
    "val_samples = technical_meta_data_df_sub['Sample'][~train_mask].values  # IDs for test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Generate training and val dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nDupTextMax = 1000\n",
    "cap_size = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df = subset_df[subset_df.srs.isin(train_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oncorhynchus mykiss    1000\n",
       "whole animal           1000\n",
       "whole organism         1000\n",
       "Danio rerio            1000\n",
       "synthetic construct    1000\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cap how many of a given entity we want to use\n",
    "train_df = train_df.sample(train_df.shape[0])\n",
    "dedup_train_df = train_df.groupby(['value']).head(n = nDupTextMax)\n",
    "dedup_train_df['value'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Balance the classes with class cap\n",
    "final_train_df = dedup_train_df.sample(dedup_train_df.shape[0]).groupby('attribute').head(n = cap_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training examples is 133627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Cell type            20000\n",
       "Tissue               20000\n",
       "Age                  20000\n",
       "Strain               20000\n",
       "Species              20000\n",
       "Genotype             14930\n",
       "Platform              7467\n",
       "Condition/Disease     5295\n",
       "Data type             3254\n",
       "Sex                   2046\n",
       "Protocol               635\n",
       "Name: attribute, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"The number of training examples is %d\" % (final_train_df.shape[0]))\n",
    "train_counts = final_train_df.attribute.value_counts()\n",
    "display(train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_df = subset_df[subset_df.srs.isin(val_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_df = val_df.sample(val_df.shape[0])\n",
    "val_df = subset_df[subset_df.srs.isin(val_samples)]\n",
    "dedup_val_df = val_df.groupby(['value']).head(n = nDupTextMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_val_df = dedup_val_df.sample(dedup_val_df.shape[0]).groupby('attribute').head(n = cap_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cell type            20000\n",
       "Tissue               20000\n",
       "Species              20000\n",
       "Age                   9292\n",
       "Strain                7908\n",
       "Genotype              4747\n",
       "Platform              1590\n",
       "Data type             1543\n",
       "Condition/Disease     1540\n",
       "Sex                    853\n",
       "Protocol               178\n",
       "Name: attribute, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_counts = final_val_df.attribute.value_counts()\n",
    "display(val_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.603887417637542"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual training and test split\n",
    "final_train_df.shape[0]/(final_train_df.shape[0] + final_val_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_train_df.to_pickle('../results/training/{model}/training_examples.pickle'.format(model = model_iter))\n",
    "final_val_df.to_pickle('../results/training/{model}/test_examples.pickle'.format(model = model_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### <font color=red>Supp. Figure 2A</font> Class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "counts_df = pd.concat([pd.DataFrame(train_counts), pd.DataFrame(val_counts)], axis=1)\n",
    "counts_df.to_csv('../doc/figures/Supplementary/Supp_Figure2A.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Model set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nr_hidden = 64 \n",
    "max_length = 7 # 95% percentile of training phrase length from NCIT\n",
    "dropout = 0.5\n",
    "learn_rate = 0.001 # General NN config\n",
    "nb_epoch = 1\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sex', 'Age', 'Cell type', 'Genotype', 'Species', 'Platform',\n",
       "       'Strain', 'Protocol', 'Condition/Disease', 'Data type', 'Tissue'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classNames = AttribToGroupNameS.unique()\n",
    "classNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(classNames)\n",
    "nr_classes=len(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lstm_shape={'nr_hidden': 64, 'max_length': max_length, 'nr_class': nr_classes}\n",
    "lstm_settings={'dropout': 0.5, 'lr': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "embeddings = nlp.vocab.vectors.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133627/133627 [00:06<00:00, 19857.20it/s]\n",
      "100%|██████████| 87651/87651 [00:03<00:00, 24748.19it/s]\n",
      "100%|██████████| 133627/133627 [00:01<00:00, 121299.51it/s]\n",
      "100%|██████████| 87651/87651 [00:00<00:00, 137156.59it/s]\n"
     ]
    }
   ],
   "source": [
    "train_texts = final_train_df.value.tolist()\n",
    "dev_texts = final_val_df.value.tolist()\n",
    "\n",
    "train_labels = keras.utils.to_categorical(le.transform(final_train_df.attribute.values))\n",
    "dev_labels = keras.utils.to_categorical(le.transform(final_val_df.attribute.values))\n",
    "\n",
    "train_docs = list(tqdm(nlp.pipe(train_texts,n_threads=32),total=len(train_texts)))\n",
    "dev_docs = list(tqdm(nlp.pipe(dev_texts,n_threads=32),total=len(dev_texts)))\n",
    "\n",
    "train_X = get_features(train_docs, lstm_shape['max_length'])\n",
    "dev_X = get_features(dev_docs, lstm_shape['max_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save('../results/training/{model}/classes.npy'.format(model = model_iter), le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = compile_lstm(embeddings, lstm_shape, lstm_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "\n",
    "with open('../results/training/11_class/model_summary.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture keras_stdout\n",
    "lstm = model.fit(train_X, train_labels, validation_data = (dev_X, dev_labels),\n",
    "          nb_epoch = nb_epoch, verbose = 1, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020_07_09'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "x = datetime.datetime.now()\n",
    "today = x.strftime(\"%Y_%m_%d\")\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lstm.model.save('../models/{model}_{date}.h5'.format(model = model_iter, date=today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "keras_stdout_str = keras_stdout.stdout\n",
    "textfile = open('../results/training/{model}/keras_out.txt'.format(model = model_iter), 'w')\n",
    "textfile.write(keras_stdout_str)\n",
    "textfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_nlp_cpu",
   "language": "python",
   "name": "deep_nlp_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
