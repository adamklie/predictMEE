{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Evaluate-trained-models\" data-toc-modified-id=\"Evaluate-trained-models-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Evaluate trained models<br></a></span><ul class=\"toc-item\"><li><span><a href=\"#Set-up\" data-toc-modified-id=\"Set-up-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Set up</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-necessry-packages\" data-toc-modified-id=\"Import-necessry-packages-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Import necessry packages</a></span></li><li><span><a href=\"#Helper-functions\" data-toc-modified-id=\"Helper-functions-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Helper functions</a></span></li><li><span><a href=\"#Plotting-parameters\" data-toc-modified-id=\"Plotting-parameters-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Plotting parameters</a></span></li><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Load data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-classes\" data-toc-modified-id=\"Load-classes-1.1.4.1\"><span class=\"toc-item-num\">1.1.4.1&nbsp;&nbsp;</span>Load classes</a></span></li><li><span><a href=\"#Load-accuracy-stats\" data-toc-modified-id=\"Load-accuracy-stats-1.1.4.2\"><span class=\"toc-item-num\">1.1.4.2&nbsp;&nbsp;</span>Load accuracy stats</a></span></li><li><span><a href=\"#Load-grouping\" data-toc-modified-id=\"Load-grouping-1.1.4.3\"><span class=\"toc-item-num\">1.1.4.3&nbsp;&nbsp;</span>Load grouping</a></span></li><li><span><a href=\"#Load-model-to-analyze`\" data-toc-modified-id=\"Load-model-to-analyze`-1.1.4.4\"><span class=\"toc-item-num\">1.1.4.4&nbsp;&nbsp;</span>Load model to analyze`</a></span></li><li><span><a href=\"#Load-NLP-model\" data-toc-modified-id=\"Load-NLP-model-1.1.4.5\"><span class=\"toc-item-num\">1.1.4.5&nbsp;&nbsp;</span>Load NLP model</a></span></li><li><span><a href=\"#Load-grouping\" data-toc-modified-id=\"Load-grouping-1.1.4.6\"><span class=\"toc-item-num\">1.1.4.6&nbsp;&nbsp;</span>Load grouping</a></span></li><li><span><a href=\"#Load-train-and-test-data\" data-toc-modified-id=\"Load-train-and-test-data-1.1.4.7\"><span class=\"toc-item-num\">1.1.4.7&nbsp;&nbsp;</span>Load train and test data</a></span></li></ul></li></ul></li><li><span><a href=\"#Analyze-current-model\" data-toc-modified-id=\"Analyze-current-model-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Analyze current model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Make-an-accuracy-dataframe-from-keras-output\" data-toc-modified-id=\"Make-an-accuracy-dataframe-from-keras-output-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Make an accuracy dataframe from keras output</a></span></li><li><span><a href=\"#Figure-4B:-Accuracy-plot\" data-toc-modified-id=\"Figure-4B:-Accuracy-plot-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span><font color=\"red\">Figure 4B:</font> Accuracy plot</a></span></li><li><span><a href=\"#Model-accuracy\" data-toc-modified-id=\"Model-accuracy-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Model accuracy</a></span><ul class=\"toc-item\"><li><span><a href=\"#Overall-accuracy\" data-toc-modified-id=\"Overall-accuracy-1.2.3.1\"><span class=\"toc-item-num\">1.2.3.1&nbsp;&nbsp;</span>Overall accuracy</a></span></li><li><span><a href=\"#Figure-4C:-Per-class-accuracy\" data-toc-modified-id=\"Figure-4C:-Per-class-accuracy-1.2.3.2\"><span class=\"toc-item-num\">1.2.3.2&nbsp;&nbsp;</span><font color=\"red\">Figure 4C:</font> Per class accuracy</a></span></li></ul></li><li><span><a href=\"#Check-correct-vs-incorrect-probabilities\" data-toc-modified-id=\"Check-correct-vs-incorrect-probabilities-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>Check correct vs incorrect probabilities</a></span></li><li><span><a href=\"#Performance-metrics\" data-toc-modified-id=\"Performance-metrics-1.2.5\"><span class=\"toc-item-num\">1.2.5&nbsp;&nbsp;</span>Performance metrics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Figure-4A:-Metrics-table\" data-toc-modified-id=\"Figure-4A:-Metrics-table-1.2.5.1\"><span class=\"toc-item-num\">1.2.5.1&nbsp;&nbsp;</span><font color=\"red\">Figure 4A:</font> Metrics table</a></span></li><li><span><a href=\"#AUC-calculation\" data-toc-modified-id=\"AUC-calculation-1.2.5.2\"><span class=\"toc-item-num\">1.2.5.2&nbsp;&nbsp;</span>AUC calculation</a></span></li><li><span><a href=\"#Figure-4D:-ROC-curve\" data-toc-modified-id=\"Figure-4D:-ROC-curve-1.2.5.3\"><span class=\"toc-item-num\">1.2.5.3&nbsp;&nbsp;</span><font color=\"red\">Figure 4D:</font> ROC curve</a></span></li></ul></li></ul></li><li><span><a href=\"#Evaluate-training-set\" data-toc-modified-id=\"Evaluate-training-set-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Evaluate training set</a></span><ul class=\"toc-item\"><li><span><a href=\"#-Supp.-Figure2B-Correlation-heatmap-between-average-embedding-vector-of-each-class-in-training-set\" data-toc-modified-id=\"-Supp.-Figure2B-Correlation-heatmap-between-average-embedding-vector-of-each-class-in-training-set-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span><font color=\"red\"> Supp. Figure2B</font> Correlation heatmap between average embedding vector of each class in training set</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate trained models<br>\n",
    "Adam Klie<br>\n",
    "07/09/2020<br>\n",
    "Script to evaluate the performance of trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Import necessry packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing, metrics\n",
    "\n",
    "import spacy\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import scipy.spatial as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_features(docs, max_length):\n",
    "    docs = list(docs)\n",
    "    Xs = np.zeros((len(docs), max_length), dtype='int32')\n",
    "    for i, doc in tqdm(enumerate(docs),total=len(docs)):\n",
    "        j = 0\n",
    "        for token in doc:\n",
    "            ##rever to word vector\n",
    "            vector_id = token.vocab.vectors.find(key=token.orth)\n",
    "            if vector_id >= 0:\n",
    "                Xs[i, j] = vector_id\n",
    "            else:\n",
    "                Xs[i, j] = 0\n",
    "            j += 1\n",
    "            if j >= max_length:\n",
    "                break\n",
    "    return Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def correlate_dataframes(df1, df2, metric = 'cosine' ):\n",
    "    M = 1 - sp.distance.cdist(df1, df2, metric)\n",
    "    return pd.DataFrame(data = M, index = df1.index, columns = df2.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Plotting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "import matplotlib as mpl\n",
    "\n",
    "rcParams['figure.figsize'] = (10, 6)\n",
    "rcParams['figure.dpi'] = 600 \n",
    "rcParams['lines.linewidth'] = 2\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "rcParams['font.size'] = 18\n",
    "rcParams['patch.edgecolor'] = 'white'\n",
    "rcParams['font.family'] = 'StixGeneral'\n",
    "\n",
    "rcParams['axes.labelsize'] = 24\n",
    "rcParams['ytick.labelsize'] = 20\n",
    "rcParams['xtick.labelsize'] = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iter = '11_class'\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.classes_ = np.load('../results/training/{model}/classes.npy'.format(model = model_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load accuracy stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/training/{model}/keras_out.txt'.format(model = model_iter), 'r') as f:\n",
    "    acc_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_df = pd.read_csv('../results/embedding/{model}/entity_merging.csv'.format(model = model_iter))\n",
    "myAttribs = grouping_df.attribute.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model to analyze`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = '11_class_2020_07_09'\n",
    "lstm = load_model(\"../models/{model}.h5\".format(model=model))\n",
    "max_length = 7\n",
    "nr_classes=len(le.classes_)\n",
    "lstm_shape={'nr_hidden': 64, 'max_length': max_length, 'nr_class': nr_classes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('../data/wikipedia-pubmed-and-PMC-w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../results/embedding/11_class_2020_07_09/entity_merging.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-23d904a4a0b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrouping_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../results/embedding/{model}/entity_merging.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmyAttribs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouping_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_nlp_cpu/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_nlp_cpu/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_nlp_cpu/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_nlp_cpu/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_nlp_cpu/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../results/embedding/11_class_2020_07_09/entity_merging.csv' does not exist"
     ]
    }
   ],
   "source": [
    "grouping_df = pd.read_csv('../results/embedding/{model}/entity_merging.csv'.format(model = model_iter))\n",
    "myAttribs = grouping_df.attribute.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('../results/training/{model}/training_examples.pickle'.format(model = model_iter))\n",
    "val_df = pd.read_pickle('../results/training/{model}/test_examples.pickle'.format(model = model_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze current model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an accuracy dataframe from keras output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = pd.DataFrame(pd.Series(acc_text.split('\\n')).str.replace('\\x08',''))\n",
    "acc_df[\"train_acc\"] = acc_df[0].str.extract('acc: (\\d+.\\d+)').values.astype('float64')\n",
    "acc_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training(x):\n",
    "    return float(int(x[0].split('/')[0])/1000)\n",
    "acc_df[\"examples_seen\"] = acc_df.apply(get_training, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>Figure 4B:</font> Accuracy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "ax.plot(acc_df.examples_seen.values, acc_df.train_acc.values, linewidth = 4)\n",
    "ax.set_xlabel('# of training examples (thousands)')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_yticks(np.arange(0.1,1.1,0.1))\n",
    "ax.grid()\n",
    "\n",
    "plt.savefig('../doc/figures/Figure4/Figure4B.eps', dpi=600, bbox_inches=\"tight\")\n",
    "plt.savefig('../doc/figures/Figure4/Figure4B.png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87651/87651 [00:03<00:00, 23728.10it/s]\n",
      "100%|██████████| 87651/87651 [00:00<00:00, 132199.42it/s]\n"
     ]
    }
   ],
   "source": [
    "val_texts = val_df.value.tolist()\n",
    "val_docs = list(tqdm(nlp.pipe(val_texts),total=len(dev_texts)))\n",
    "val_X = get_features(val_docs,lstm_shape['max_length'])\n",
    "predictM = lstm.predict_proba(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "probaDf_multI = pd.DataFrame(data = predictM, columns = le.classes_)\n",
    "probaDf_multI.index = pd.MultiIndex.from_arrays([val_df.attribute.values, dev_texts], names=['entity','text'])\n",
    "probaDf = probaDf_multI.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "myClasses = grouping_df.GroupName.unique()\n",
    "predicted_types = probaDf.loc[:, probaDf.columns.isin(myClasses)].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8521180591208315\n"
     ]
    }
   ],
   "source": [
    "overall_acc = ((probaDf.entity == predicted_types).mean())\n",
    "print('Accuracy:', overall_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color =red>Figure 4C:</font> Per class accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inEvalDf = probaDf_multI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "minProbThreshold = 0.2\n",
    "confidence_mask = inEvalDf.max(axis=1)>=minProbThreshold\n",
    "tmpDf3 = inEvalDf.idxmax(axis=1).reset_index(name='predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "continDf=tmpDf3.groupby(['predicted','entity']).size().unstack().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "continDf=continDf.loc[le.classes_, le.classes_]\n",
    "continDf.index=continDf.index.copy()\n",
    "continDf.columns=continDf.columns.copy()\n",
    "continDf.index.name='Predicted'\n",
    "continDf.columns.name='Actual'\n",
    "percentDf=(continDf/continDf.sum(axis=0)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(20,10))\n",
    "#g.data2d.columns=g.data2d.columns.copy()\n",
    "#g.data2d.index=g.data2d.index.copy()\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "sns.heatmap(data=percentDf,annot=True,fmt='0.0%', annot_kws={\"fontsize\":20})\n",
    "ax.set_ylabel('Ground truth', fontsize = 24)\n",
    "ax.set_xlabel('Predicted', fontsize = 24)\n",
    "\n",
    "plt.savefig('../doc/figures/Figure4/Figure4C.eps', dpi=600, bbox_inches=\"tight\")\n",
    "plt.savefig('../doc/figures/Figure4/Figure4C.png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check correct vs incorrect probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_df = probaDf[probaDf.entity != predicted_types][['entity','text']]\n",
    "incorrect_df['predicted'] = predicted_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "contdf_long=percentDf.stack().reset_index(name='Percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Strain</td>\n",
       "      <td>Species</td>\n",
       "      <td>0.063986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Sex</td>\n",
       "      <td>Strain</td>\n",
       "      <td>0.069168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Platform</td>\n",
       "      <td>Strain</td>\n",
       "      <td>0.079245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Condition/Disease</td>\n",
       "      <td>Tissue</td>\n",
       "      <td>0.104545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Genotype</td>\n",
       "      <td>Strain</td>\n",
       "      <td>0.115441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Protocol</td>\n",
       "      <td>Tissue</td>\n",
       "      <td>0.117978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Tissue</td>\n",
       "      <td>Cell type</td>\n",
       "      <td>0.145150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Protocol</td>\n",
       "      <td>Genotype</td>\n",
       "      <td>0.157303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cell type</td>\n",
       "      <td>Tissue</td>\n",
       "      <td>0.219650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Protocol</td>\n",
       "      <td>Cell type</td>\n",
       "      <td>0.606742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Actual  Predicted   Percent\n",
       "107             Strain    Species  0.063986\n",
       "86                 Sex     Strain  0.069168\n",
       "64            Platform     Strain  0.079245\n",
       "32   Condition/Disease     Tissue  0.104545\n",
       "53            Genotype     Strain  0.115441\n",
       "76            Protocol     Tissue  0.117978\n",
       "111             Tissue  Cell type  0.145150\n",
       "70            Protocol   Genotype  0.157303\n",
       "21           Cell type     Tissue  0.219650\n",
       "67            Protocol  Cell type  0.606742"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contdf_wrong=contdf_long[contdf_long.Actual!=contdf_long.Predicted].sort_values('Percent')\n",
    "contdf_wrong[contdf_wrong.Percent>0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16, 16))\n",
    "# predDf=probaDf_multI.stack().reset_index()\n",
    "# predDf.columns=['entity','text','predicted','proba']\n",
    "# predDf['match'] = (predDf.entity == predDf.predicted)\n",
    "# g =sns.boxplot(data=predDf,x='entity',y='proba', hue='match', showfliers=False)\n",
    "# g.set_xticklabels(g.get_xticklabels(), rotation=45)\n",
    "# predDf[predDf['match']].groupby(['entity'])['proba'].quantile(0.25).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color =red>Figure 4A:</font> Metrics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inTmpDf=inEvalDf.idxmax(axis=1).reset_index(name='predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inTmpDf['correct']=inTmpDf.entity==inTmpDf.predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entity\n",
       "Protocol             0.000000\n",
       "Cell type            0.694900\n",
       "Condition/Disease    0.748052\n",
       "Tissue               0.823600\n",
       "Strain               0.835483\n",
       "Genotype             0.854856\n",
       "Platform             0.920755\n",
       "Sex                  0.928488\n",
       "Species              0.979600\n",
       "Age                  0.980521\n",
       "Data type            1.000000\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inTmpDf.groupby('entity')['correct'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_r_f1 = metrics.precision_recall_fscore_support(y_true=inTmpDf['entity'],y_pred=inTmpDf['predicted'],average='weighted')\n",
    "metric_df = pd.DataFrame({'Accuracy':overall_acc, \n",
    "                          'Precision':p_r_f1[0], \n",
    "                          'Recall':p_r_f1[1], \n",
    "                          'F1 Score':p_r_f1[2]}, index=[0])\n",
    "metric_df.to_csv('../doc/figures/Figure4/Figure4A.csv')\n",
    "metric_df.to_csv('../results/training/{model}/metrics.csv'.format(model=model_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8507908781160782, 0.8521180591208315, 0.8501662653185019, None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_r_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = preprocessing.label_binarize(inTmpDf.entity.values, classes=le.classes_)\n",
    "y_score = probaDf[le.classes_].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr_dict = dict()\n",
    "tpr_dict = dict()\n",
    "roc_auc_dict = dict()\n",
    "for i, class_ in enumerate(le.classes_):\n",
    "    fpr_dict[class_], tpr_dict[class_], _ = metrics.roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc_dict[class_] = metrics.auc(fpr_dict[class_], tpr_dict[class_])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_dict[\"Micro\"], tpr_dict[\"Micro\"], _ = metrics.roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc_dict[\"Micro\"] = metrics.auc(fpr_dict[\"Micro\"], tpr_dict[\"Micro\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color =red>Figure 4D:</font> ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(16, 6))\n",
    "for myClass in roc_auc_dict:\n",
    "    if myClass == \"Micro\":\n",
    "        lw = 4\n",
    "    else:\n",
    "        lw = 1\n",
    "    fpr = fpr_dict[myClass]\n",
    "    tpr = tpr_dict[myClass]\n",
    "    ax.plot(fpr, tpr, linewidth = lw,\n",
    "            label=\"{myClass} ({AUC})\".format(myClass=myClass, AUC=str(metrics.auc(fpr,tpr))[:5]))\n",
    "    \n",
    "ax.set_xlabel('False positive rate', fontsize = 24)\n",
    "ax.set_ylabel('True positive rate', fontsize = 24)\n",
    "plt.legend(fontsize='16', ncol=2, handleheight=2.4, labelspacing=0.05)\n",
    "ax.plot([0,1], [0,1], '--', alpha=0.5, zorder=0, color='gray')\n",
    "plt.savefig('../doc/figures/Figure4/Figure4D.eps', dpi=600, bbox_inches=\"tight\")\n",
    "plt.savefig('../doc/figures/Figure4/Figure4D.png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red> Supp. Figure2B</font> Correlation heatmap between average embedding vector of each class in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word2Vec for all attributes\n",
    "docs = nlp.pipe(train_df['value'].tolist())\n",
    "vectors = [doc.vector for doc in docs]\n",
    "doc_vector_df = pd.DataFrame(vectors, index = train_df.set_index(['srs','attribute','value']).index).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cosine similarity of these classes\n",
    "attribute_means = doc_vector_df.groupby('attribute').mean()\n",
    "embedding_df = attribute_means[attribute_means.sum(axis=1).abs()>0]\n",
    "corr_df = correlate_dataframes(embedding_df, embedding_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(data=corr_df,annot=True,fmt='0.1f', \n",
    "               cbar_kws={'label':'cosine similarity'}, \n",
    "               center=0.1, annot_kws={\"fontsize\":15})\n",
    "ax.set_ylabel('Ground truth', fontsize = 24)\n",
    "ax.set_xlabel('Predicted', fontsize = 24)\n",
    "plt.savefig('../doc/figures/Supplementary/Supp_Figure2B.eps', dpi=600, bbox_inches=\"tight\")\n",
    "plt.savefig('../doc/figures/Supplementary/Supp_Figure2B.png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.close();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_nlp_cpu",
   "language": "python",
   "name": "deep_nlp_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
