{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Evaluate-trained-models\" data-toc-modified-id=\"Evaluate-trained-models-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Evaluate trained models<br></a></span><ul class=\"toc-item\"><li><span><a href=\"#Set-up\" data-toc-modified-id=\"Set-up-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Set up</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-necessry-packages\" data-toc-modified-id=\"Import-necessry-packages-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Import necessry packages</a></span></li><li><span><a href=\"#Helper-functions\" data-toc-modified-id=\"Helper-functions-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Helper functions</a></span></li><li><span><a href=\"#Plotting-parameters\" data-toc-modified-id=\"Plotting-parameters-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Plotting parameters</a></span></li><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Load data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-classes\" data-toc-modified-id=\"Load-classes-1.1.4.1\"><span class=\"toc-item-num\">1.1.4.1&nbsp;&nbsp;</span>Load classes</a></span></li><li><span><a href=\"#Load-accuracy-stats\" data-toc-modified-id=\"Load-accuracy-stats-1.1.4.2\"><span class=\"toc-item-num\">1.1.4.2&nbsp;&nbsp;</span>Load accuracy stats</a></span></li><li><span><a href=\"#Load-grouping\" data-toc-modified-id=\"Load-grouping-1.1.4.3\"><span class=\"toc-item-num\">1.1.4.3&nbsp;&nbsp;</span>Load grouping</a></span></li><li><span><a href=\"#Load-model-to-analyze`\" data-toc-modified-id=\"Load-model-to-analyze`-1.1.4.4\"><span class=\"toc-item-num\">1.1.4.4&nbsp;&nbsp;</span>Load model to analyze`</a></span></li><li><span><a href=\"#Load-NLP-model\" data-toc-modified-id=\"Load-NLP-model-1.1.4.5\"><span class=\"toc-item-num\">1.1.4.5&nbsp;&nbsp;</span>Load NLP model</a></span></li><li><span><a href=\"#Load-grouping\" data-toc-modified-id=\"Load-grouping-1.1.4.6\"><span class=\"toc-item-num\">1.1.4.6&nbsp;&nbsp;</span>Load grouping</a></span></li><li><span><a href=\"#Load-train-and-test-data\" data-toc-modified-id=\"Load-train-and-test-data-1.1.4.7\"><span class=\"toc-item-num\">1.1.4.7&nbsp;&nbsp;</span>Load train and test data</a></span></li></ul></li></ul></li><li><span><a href=\"#Analyze-current-model\" data-toc-modified-id=\"Analyze-current-model-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Analyze current model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Make-an-accuracy-dataframe-from-keras-output\" data-toc-modified-id=\"Make-an-accuracy-dataframe-from-keras-output-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Make an accuracy dataframe from keras output</a></span></li><li><span><a href=\"#Figure-4B:-Accuracy-plot\" data-toc-modified-id=\"Figure-4B:-Accuracy-plot-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span><font color=\"red\">Figure 4B:</font> Accuracy plot</a></span></li><li><span><a href=\"#Model-accuracy\" data-toc-modified-id=\"Model-accuracy-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Model accuracy</a></span><ul class=\"toc-item\"><li><span><a href=\"#Overall-accuracy\" data-toc-modified-id=\"Overall-accuracy-1.2.3.1\"><span class=\"toc-item-num\">1.2.3.1&nbsp;&nbsp;</span>Overall accuracy</a></span></li><li><span><a href=\"#Figure-4C:-Per-class-accuracy\" data-toc-modified-id=\"Figure-4C:-Per-class-accuracy-1.2.3.2\"><span class=\"toc-item-num\">1.2.3.2&nbsp;&nbsp;</span><font color=\"red\">Figure 4C:</font> Per class accuracy</a></span></li></ul></li><li><span><a href=\"#Check-correct-vs-incorrect-probabilities\" data-toc-modified-id=\"Check-correct-vs-incorrect-probabilities-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>Check correct vs incorrect probabilities</a></span></li><li><span><a href=\"#Performance-metrics\" data-toc-modified-id=\"Performance-metrics-1.2.5\"><span class=\"toc-item-num\">1.2.5&nbsp;&nbsp;</span>Performance metrics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Figure-4A:-Metrics-table\" data-toc-modified-id=\"Figure-4A:-Metrics-table-1.2.5.1\"><span class=\"toc-item-num\">1.2.5.1&nbsp;&nbsp;</span><font color=\"red\">Figure 4A:</font> Metrics table</a></span></li><li><span><a href=\"#AUC-calculation\" data-toc-modified-id=\"AUC-calculation-1.2.5.2\"><span class=\"toc-item-num\">1.2.5.2&nbsp;&nbsp;</span>AUC calculation</a></span></li><li><span><a href=\"#Figure-4D:-ROC-curve\" data-toc-modified-id=\"Figure-4D:-ROC-curve-1.2.5.3\"><span class=\"toc-item-num\">1.2.5.3&nbsp;&nbsp;</span><font color=\"red\">Figure 4D:</font> ROC curve</a></span></li></ul></li></ul></li><li><span><a href=\"#Evaluate-training-set\" data-toc-modified-id=\"Evaluate-training-set-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Evaluate training set</a></span><ul class=\"toc-item\"><li><span><a href=\"#-Supp.-Figure2B-Correlation-heatmap-between-average-embedding-vector-of-each-class-in-training-set\" data-toc-modified-id=\"-Supp.-Figure2B-Correlation-heatmap-between-average-embedding-vector-of-each-class-in-training-set-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span><font color=\"red\"> Supp. Figure2B</font> Correlation heatmap between average embedding vector of each class in training set</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate trained models<br>\n",
    "Adam Klie<br>\n",
    "07/09/2020<br>\n",
    "Script to evaluate the performance of trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessry packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing, metrics\n",
    "\n",
    "import spacy\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import scipy.spatial as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(docs, max_length):\n",
    "    docs = list(docs)\n",
    "    Xs = np.zeros((len(docs), max_length), dtype='int32')\n",
    "    for i, doc in tqdm(enumerate(docs),total=len(docs)):\n",
    "        j = 0\n",
    "        for token in doc:\n",
    "            ##rever to word vector\n",
    "            vector_id = token.vocab.vectors.find(key=token.orth)\n",
    "            if vector_id >= 0:\n",
    "                Xs[i, j] = vector_id\n",
    "            else:\n",
    "                Xs[i, j] = 0\n",
    "            j += 1\n",
    "            if j >= max_length:\n",
    "                break\n",
    "    return Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate_dataframes(df1, df2, metric = 'cosine' ):\n",
    "    M = 1 - sp.distance.cdist(df1, df2, metric)\n",
    "    return pd.DataFrame(data = M, index = df1.index, columns = df2.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "import matplotlib as mpl\n",
    "\n",
    "rcParams['figure.figsize'] = (10, 6)\n",
    "rcParams['figure.dpi'] = 600 \n",
    "rcParams['lines.linewidth'] = 2\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "rcParams['font.size'] = 18\n",
    "rcParams['patch.edgecolor'] = 'white'\n",
    "rcParams['font.family'] = 'StixGeneral'\n",
    "\n",
    "rcParams['axes.labelsize'] = 36\n",
    "rcParams['ytick.labelsize'] = 30\n",
    "rcParams['xtick.labelsize'] = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iter = '11_class'\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.classes_ = np.load('../results/training/{model}/classes.npy'.format(model = model_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load accuracy stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/training/{model}/keras_out.txt'.format(model = model_iter), 'r') as f:\n",
    "    acc_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_df = pd.read_csv('../results/embedding/{model}/entity_merging.csv'.format(model = model_iter))\n",
    "myAttribs = grouping_df.attribute.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model to analyze`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = '11_class_2020_07_09'\n",
    "lstm = load_model(\"../models/{model}.h5\".format(model=model))\n",
    "max_length = 7\n",
    "nr_classes=len(le.classes_)\n",
    "lstm_shape={'nr_hidden': 64, 'max_length': max_length, 'nr_class': nr_classes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/cellar/users/aklie/miniconda3/envs/deep_nlp_cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('../data/wikipedia-pubmed-and-PMC-w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_df = pd.read_csv('../results/embedding/{model}/entity_merging.csv'.format(model = model_iter))\n",
    "myAttribs = grouping_df.attribute.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('../results/training/{model}/training_examples.pickle'.format(model = model_iter))\n",
    "val_df = pd.read_pickle('../results/training/{model}/test_examples.pickle'.format(model = model_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze current model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an accuracy dataframe from keras output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = pd.DataFrame(pd.Series(acc_text.split('\\n')).str.replace('\\x08',''))\n",
    "acc_df[\"train_acc\"] = acc_df[0].str.extract('acc: (\\d+.\\d+)').values.astype('float64')\n",
    "acc_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training(x):\n",
    "    return float(int(x[0].split('/')[0])/1000)\n",
    "acc_df[\"examples_seen\"] = acc_df.apply(get_training, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>Figure 4B:</font> Accuracy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "ax.plot(acc_df.examples_seen.values, acc_df.train_acc.values, linewidth = 4)\n",
    "ax.set_xlabel('# of training examples (thousands)')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_yticks(np.arange(0.1,1.1,0.1))\n",
    "ax.grid()\n",
    "\n",
    "plt.savefig('../doc/figures/Figure4/Figure4B.eps', dpi=600, bbox_inches=\"tight\")\n",
    "plt.savefig('../doc/figures/Figure4/Figure4B.png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_texts = val_df.value.tolist()\n",
    "val_docs = list(tqdm(nlp.pipe(val_texts),total=len(val_texts)))\n",
    "val_X = get_features(val_docs,lstm_shape['max_length'])\n",
    "predictM = lstm.predict_proba(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probaDf_multI = pd.DataFrame(data = predictM, columns = le.classes_)\n",
    "probaDf_multI.index = pd.MultiIndex.from_arrays([val_df.attribute.values, val_texts], names=['entity','text'])\n",
    "probaDf = probaDf_multI.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myClasses = grouping_df.GroupName.unique()\n",
    "predicted_types = probaDf.loc[:, probaDf.columns.isin(myClasses)].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overall_acc = ((probaDf.entity == predicted_types).mean())\n",
    "print('Accuracy:', overall_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color =red>Figure 4C:</font> Per class accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inEvalDf = probaDf_multI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minProbThreshold = 0.2\n",
    "confidence_mask = inEvalDf.max(axis=1)>=minProbThreshold\n",
    "tmpDf3 = inEvalDf.idxmax(axis=1).reset_index(name='predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continDf=tmpDf3.groupby(['predicted','entity']).size().unstack().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continDf=continDf.loc[le.classes_, le.classes_]\n",
    "continDf.index=continDf.index.copy()\n",
    "continDf.columns=continDf.columns.copy()\n",
    "continDf.index.name='Predicted'\n",
    "continDf.columns.name='Actual'\n",
    "percentDf=(continDf/continDf.sum(axis=0)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(24,10))\n",
    "#g.data2d.columns=g.data2d.columns.copy()\n",
    "#g.data2d.index=g.data2d.index.copy()\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "sns.heatmap(data=percentDf,annot=True,fmt='0.0%', annot_kws={\"fontsize\":16})\n",
    "ax.set_ylabel('Ground truth', fontsize = 36)\n",
    "ax.set_xlabel('Predicted', fontsize = 36)\n",
    "\n",
    "plt.savefig('../doc/figures/Figure4/Figure4D_new.eps', dpi=600, bbox_inches=\"tight\")\n",
    "plt.savefig('../doc/figures/Figure4/Figure4D_new.png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check correct vs incorrect probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_df = probaDf[probaDf.entity != predicted_types][['entity','text']]\n",
    "incorrect_df['predicted'] = predicted_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contdf_long=percentDf.stack().reset_index(name='Percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contdf_wrong=contdf_long[contdf_long.Actual!=contdf_long.Predicted].sort_values('Percent')\n",
    "contdf_wrong[contdf_wrong.Percent>0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16, 16))\n",
    "# predDf=probaDf_multI.stack().reset_index()\n",
    "# predDf.columns=['entity','text','predicted','proba']\n",
    "# predDf['match'] = (predDf.entity == predDf.predicted)\n",
    "# g =sns.boxplot(data=predDf,x='entity',y='proba', hue='match', showfliers=False)\n",
    "# g.set_xticklabels(g.get_xticklabels(), rotation=45)\n",
    "# predDf[predDf['match']].groupby(['entity'])['proba'].quantile(0.25).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color =red>Figure 4A:</font> Metrics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inTmpDf=inEvalDf.idxmax(axis=1).reset_index(name='predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inTmpDf['correct']=inTmpDf.entity==inTmpDf.predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inTmpDf.groupby('entity')['correct'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_r_f1 = metrics.precision_recall_fscore_support(y_true=inTmpDf['entity'],y_pred=inTmpDf['predicted'],average='weighted')\n",
    "metric_df = pd.DataFrame({'Accuracy':overall_acc, \n",
    "                          'Precision':p_r_f1[0], \n",
    "                          'Recall':p_r_f1[1], \n",
    "                          'F1 Score':p_r_f1[2]}, index=[0])\n",
    "metric_df.to_csv('../doc/figures/Figure4/Figure4A.csv')\n",
    "metric_df.to_csv('../results/training/{model}/metrics.csv'.format(model=model_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_r_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = preprocessing.label_binarize(inTmpDf.entity.values, classes=le.classes_)\n",
    "y_score = probaDf[le.classes_].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr_dict = dict()\n",
    "tpr_dict = dict()\n",
    "roc_auc_dict = dict()\n",
    "for i, class_ in enumerate(le.classes_):\n",
    "    fpr_dict[class_], tpr_dict[class_], _ = metrics.roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc_dict[class_] = metrics.auc(fpr_dict[class_], tpr_dict[class_])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_dict[\"Micro\"], tpr_dict[\"Micro\"], _ = metrics.roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc_dict[\"Micro\"] = metrics.auc(fpr_dict[\"Micro\"], tpr_dict[\"Micro\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color =red>Figure 4D:</font> ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(16, 6))\n",
    "for myClass in roc_auc_dict:\n",
    "    if myClass == \"Micro\":\n",
    "        lw = 4\n",
    "    else:\n",
    "        lw = 1\n",
    "    fpr = fpr_dict[myClass]\n",
    "    tpr = tpr_dict[myClass]\n",
    "    ax.plot(fpr, tpr, linewidth = lw,\n",
    "            label=\"{myClass} ({AUC})\".format(myClass=myClass, AUC=str(metrics.auc(fpr,tpr))[:5]))\n",
    "    \n",
    "ax.set_xlabel('False positive rate', fontsize = 24)\n",
    "ax.set_ylabel('True positive rate', fontsize = 24)\n",
    "plt.legend(fontsize='16', ncol=2, handleheight=2.4, labelspacing=0.05)\n",
    "ax.plot([0,1], [0,1], '--', alpha=0.5, zorder=0, color='gray')\n",
    "plt.savefig('../doc/figures/Figure4/Figure4D.eps', dpi=600, bbox_inches=\"tight\")\n",
    "plt.savefig('../doc/figures/Figure4/Figure4D.png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red> Supp. Figure2B</font> Correlation heatmap between average embedding vector of each class in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word2Vec for all attributes\n",
    "docs = nlp.pipe(train_df['value'].tolist())\n",
    "vectors = [doc.vector for doc in docs]\n",
    "doc_vector_df = pd.DataFrame(vectors, index = train_df.set_index(['srs','attribute','value']).index).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cosine similarity of these classes\n",
    "attribute_means = doc_vector_df.groupby('attribute').mean()\n",
    "embedding_df = attribute_means[attribute_means.sum(axis=1).abs()>0]\n",
    "corr_df = correlate_dataframes(embedding_df, embedding_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(data=corr_df,annot=True,fmt='0.1f', \n",
    "               cbar_kws={'label':'cosine similarity'}, \n",
    "               center=0.1, annot_kws={\"fontsize\":15})\n",
    "ax.set_ylabel('Ground truth', fontsize = 24)\n",
    "ax.set_xlabel('Predicted', fontsize = 24)\n",
    "plt.savefig('../doc/figures/Supplementary/Supp_Figure2B.eps', dpi=600, bbox_inches=\"tight\")\n",
    "plt.savefig('../doc/figures/Supplementary/Supp_Figure2B.png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.sum(axis=1).sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_nlp_cpu",
   "language": "python",
   "name": "deep_nlp_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
